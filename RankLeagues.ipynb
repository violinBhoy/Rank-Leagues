{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/violinBhoy/Rank-Leagues/blob/main/RankLeagues.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "dqVUeRBI8S1m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZqZd0vOV4-jd"
      },
      "outputs": [],
      "source": [
        "#tie the league numbers to a country\n",
        "leagues = {\n",
        "    0:\"england\",\n",
        "    1:\"scotland\",\n",
        "    2: \"republic of ireland\",\n",
        "    3: \"portugal\",\n",
        "    4: \"spain\",\n",
        "    5: \"italy\",\n",
        "    6: \"switzerland\",\n",
        "    7: \"austria\",\n",
        "    8: \"germany\",\n",
        "    9: \"czech republic\",\n",
        "    10: \"poland\",\n",
        "    11: \"slovakia\",\n",
        "    12: \"hungary\",\n",
        "    13: \"slovenia\",\n",
        "    14: \"croatia\",\n",
        "    15: \"bosnia\",\n",
        "    16: \"montenegro\",\n",
        "    17: \"albania\",\n",
        "    18: \"greece\",\n",
        "    19: \"serbia\",\n",
        "    20: \"north macedonia\",\n",
        "    21: \"bulgaria\",\n",
        "    22: \"romania\",\n",
        "    23: \"moldova\",\n",
        "    24: \"turkey\",\n",
        "    25: \"ukraine\",\n",
        "    26: \"belarus\",\n",
        "    27: \"lithuania\",\n",
        "    28: \"latvia\",\n",
        "    29: \"estonia\",\n",
        "    30: \"norway\",\n",
        "    31: \"sweden\",\n",
        "    32: \"finland\",\n",
        "    33: \"belgium\",\n",
        "    34: \"netherlands\",\n",
        "    35: \"france\",\n",
        "    36: \"denmark\",\n",
        "    37: \"israel\",\n",
        "    38: \"azerbaijan\",\n",
        "    39: \"cyprus\",\n",
        "    40: \"iceland\",\n",
        "    41: \"kazakhstan\",\n",
        "    42: \"armenia\",\n",
        "    43: \"wales\",\n",
        "    44: \"northern ireland\",\n",
        "    45: \"georgia\",\n",
        "    46: \"luxembourg\",\n",
        "    47: \"MLS\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Centroid: the middle of the cluster"
      ],
      "metadata": {
        "id": "eUWx9_b-Kkk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/violinBhoy/dataForML/refs/heads/main/leagues.csv\")\n",
        "\n",
        "# put the features into an array\n",
        "features = df[['squad_difference', 'num_winners', 'squad_average', 'internationals', 'points_difference']].values\n",
        "\n",
        "# scale the data\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "scaled_features_array = np.array(scaled_features)\n",
        "\n",
        "# multiply a feature by 10\n",
        "scaled_features_array[:, 0] *= 1\n",
        "scaled_features_array[:, 1] *= 1\n",
        "scaled_features_array[:, 2] *= 1\n",
        "scaled_features_array[:, 3] *= 1\n",
        "scaled_features_array[:, 4] *= 1\n",
        "\n",
        "# Convert back to tensor\n",
        "X = tf.convert_to_tensor(scaled_features_array, dtype=tf.float32)\n",
        "\n",
        "# parameters\n",
        "num_clusters = 4\n",
        "num_iterations = 100\n",
        "# Define random initial centroids\n",
        "#random numbers of num_clusters with a length of scaled_features of type int to create centroids\n",
        "points_idx = tf.random.uniform([num_clusters], 0, len(scaled_features_array), dtype=tf.int32)\n",
        "# make the centroid one of the points\n",
        "centroids = tf.gather(X, points_idx)\n",
        "\n",
        "# K-means algorithm\n",
        "for i in range(num_iterations):\n",
        "    # Expand dimensions to compute distances between each point and centroid\n",
        "    expanded_X = tf.expand_dims(X, 1)  # Shape becomes (n_samples, 1, n_features)\n",
        "    expanded_centroids = tf.expand_dims(centroids, 0)  # Shape becomes (1, n_clusters, n_features)\n",
        "\n",
        "    # Calculate Euclidean distances - distances between points\n",
        "    distances = tf.reduce_sum(tf.square(expanded_X - expanded_centroids), axis=2)\n",
        "\n",
        "    # assign the points to a centroid\n",
        "    assignments = tf.argmin(distances, axis=1)\n",
        "\n",
        "    # Update centroids based on assignments\n",
        "    new_centroids = []\n",
        "    for i in range(num_clusters):\n",
        "        # Get points assigned to this cluster\n",
        "        mask = tf.equal(assignments, i) #identify what the goes to what with boolean mask\n",
        "        cluster_points = tf.boolean_mask(X, mask) #apply the mask to the points\n",
        "\n",
        "        # If the cluster is not empty, update its centroid\n",
        "        # find the average of the points, that is the centroid\n",
        "        if tf.size(cluster_points) > 0:\n",
        "            new_centroids.append(tf.reduce_mean(cluster_points, axis=0))\n",
        "        else:\n",
        "            # Keep the old centroid if no points are assigned to this cluster\n",
        "            new_centroids.append(centroids[i])\n",
        "\n",
        "    #put the centroids into one tf stack\n",
        "    new_centroids = tf.stack(new_centroids)\n",
        "    #if the centroids haven't changed, we found the right one\n",
        "    if tf.reduce_all(tf.equal(centroids, new_centroids)):\n",
        "        break\n",
        "\n",
        "    centroids = new_centroids\n",
        "    #num_iterations += 1\n",
        "\n",
        "# Final cluster assignments\n",
        "final_assignments = tf.argmin(tf.reduce_sum(tf.square(tf.expand_dims(X, 1) - tf.expand_dims(centroids, 0)), axis=2), axis=1)\n",
        "\n",
        "print(final_assignments)\n",
        "\n",
        "# give the data frame the assignments\n",
        "df['cluster'] = final_assignments.numpy()\n",
        "\n",
        "# Print some statistics about the clusters\n",
        "total_size = 0\n",
        "for i in range(num_clusters):\n",
        "    cluster_size = np.sum(df['cluster'] == i)\n",
        "    total_size += cluster_size\n",
        "    print(f\"Cluster {i} contains {cluster_size} samples\")\n",
        "\n",
        "cluster0 = []\n",
        "cluster1 = []\n",
        "cluster2 = []\n",
        "cluster3 = []\n",
        "\n",
        "for i in range(total_size):\n",
        "  if final_assignments[i] == 0:\n",
        "    cluster0.append(leagues[i])\n",
        "  elif final_assignments[i] == 1:\n",
        "    cluster1.append(leagues[i])\n",
        "  elif final_assignments[i] == 2:\n",
        "    cluster2.append(leagues[i])\n",
        "  elif final_assignments[i] == 3:\n",
        "    cluster3.append(leagues[i])\n",
        "\n",
        "print(cluster0)\n",
        "print(cluster1)\n",
        "print(cluster2)\n",
        "print(cluster3)\n",
        "print(num_iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtscH57f7TcU",
        "outputId": "11b64557-1b94-4e4c-c517-1c9ac451c0b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[3 2 0 1 3 3 2 2 3 2 0 2 2 0 2 2 0 0 2 2 0 2 0 0 1 2 2 0 2 2 0 0 0 1 1 3 0\n",
            " 2 2 2 0 0 2 2 2 0 2 1], shape=(48,), dtype=int64)\n",
            "Cluster 0 contains 16 samples\n",
            "Cluster 1 contains 5 samples\n",
            "Cluster 2 contains 22 samples\n",
            "Cluster 3 contains 5 samples\n",
            "['republic of ireland', 'poland', 'slovenia', 'montenegro', 'albania', 'north macedonia', 'romania', 'moldova', 'lithuania', 'norway', 'sweden', 'finland', 'denmark', 'iceland', 'kazakhstan', 'georgia']\n",
            "['portugal', 'turkey', 'belgium', 'netherlands', 'MLS']\n",
            "['scotland', 'switzerland', 'austria', 'czech republic', 'slovakia', 'hungary', 'croatia', 'bosnia', 'greece', 'serbia', 'bulgaria', 'ukraine', 'belarus', 'latvia', 'estonia', 'israel', 'azerbaijan', 'cyprus', 'armenia', 'wales', 'northern ireland', 'luxembourg']\n",
            "['england', 'spain', 'italy', 'germany', 'france']\n",
            "100\n"
          ]
        }
      ]
    }
  ]
}